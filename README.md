## 1. AdaptiveResEncoder

'
encode_weight = torch.zeros((num_encoder_layers, d_model), device='cuda')
encode_weight[-1, :] = torch.ones((d_model), device='cuda')
self.encode_weight = nn.Parameter(encode_weight, requires_grad=True)
...
for i in range(6):
            mem += inter_mem[i] * self.encode_weight[i]
'

Compare with DeTr

DeTr: Epoch 0:"train_lr": 9.999999999999342e-05, "train_class_error": 89.00132779228738, "train_loss": 25.428831253216895, "train_loss_bbox": 1.141616935950595, "train_loss_bbox_0": 1.1871701720376293, "train_loss_bbox_1": 1.1554074858948267, "train_loss_bbox_2": 1.1439687113450978, "train_loss_bbox_3": 1.137943878802128, "train_loss_bbox_4": 1.1363896374385078, "train_loss_ce": 1.5075451776998126, "train_loss_ce_0": 1.5827832080391577, "train_loss_ce_1": 1.545520452064869, "train_loss_ce_2": 1.5272149658112815, "train_loss_ce_3": 1.5174654086656643, "train_loss_ce_4": 1.512690750325655, "train_loss_giou": 1.5496716783805327, "train_loss_giou_0": 1.5780433469907547, "train_loss_giou_1": 1.559824980988905, "train_loss_giou_2": 1.5517085842884981, "train_loss_giou_3": 1.5462578174807293, "train_loss_giou_4": 1.5476080747200298, "train_cardinality_error_unscaled": 7.935445413961039, "train_cardinality_error_0_unscaled": 7.70012344426407, "train_cardinality_error_1_unscaled": 7.736556412337662, "train_cardinality_error_2_unscaled": 7.717244994588745, "train_cardinality_error_3_unscaled": 7.795522186147186, "train_cardinality_error_4_unscaled": 7.856246617965368, "train_class_error_unscaled": 89.00132779228738, "train_loss_bbox_unscaled": 0.2283233871030343, "train_loss_bbox_0_unscaled": 0.23743403444542385, "train_loss_bbox_1_unscaled": 0.2310814970249544, "train_loss_bbox_2_unscaled": 0.2287937422762766, "train_loss_bbox_3_unscaled": 0.22758877592249996, "train_loss_bbox_4_unscaled": 0.22727792757236726, "train_loss_ce_unscaled": 1.5075451776998126, "train_loss_ce_0_unscaled": 1.5827832080391577, "train_loss_ce_1_unscaled": 1.545520452064869, "train_loss_ce_2_unscaled": 1.5272149658112815, "train_loss_ce_3_unscaled": 1.5174654086656643, "train_loss_ce_4_unscaled": 1.512690750325655, "train_loss_giou_unscaled": 0.7748358391902663, "train_loss_giou_0_unscaled": 0.7890216734953773, "train_loss_giou_1_unscaled": 0.7799124904944525, "train_loss_giou_2_unscaled": 0.7758542921442491, "train_loss_giou_3_unscaled": 0.7731289087403647, "train_loss_giou_4_unscaled": 0.7738040373600149, "test_class_error": 80.61580662818471, "test_loss": 28.39839132272514, "test_loss_bbox": 1.1101688678097572, "test_loss_bbox_0": 2.0522844032117518, "test_loss_bbox_1": 1.7690094071588698, "test_loss_bbox_2": 1.4350026625736503, "test_loss_bbox_3": 1.311189791958803, "test_loss_bbox_4": 1.1831550450082038, "test_loss_ce": 1.370138221865247, "test_loss_ce_0": 1.4795395280145536, "test_loss_ce_1": 1.463806616272896, "test_loss_ce_2": 1.4175632497307602, "test_loss_ce_3": 1.3968758446395777, "test_loss_ce_4": 1.383345760737255, "test_loss_giou": 1.5733277395272711, "test_loss_giou_0": 2.2133696329821446, "test_loss_giou_1": 1.9855036074948158, "test_loss_giou_2": 1.8301344411388325, "test_loss_giou_3": 1.7539237532646033, "test_loss_giou_4": 1.6700529771245969, "test_cardinality_error_unscaled": 13.492834394904458, "test_cardinality_error_0_unscaled": 18.508757961783438, "test_cardinality_error_1_unscaled": 19.818471337579616, "test_cardinality_error_2_unscaled": 17.193869426751593, "test_cardinality_error_3_unscaled": 15.385350318471337, "test_cardinality_error_4_unscaled": 12.799164012738853, "test_class_error_unscaled": 80.61580662818471, "test_loss_bbox_unscaled": 0.2220337728785861, "test_loss_bbox_0_unscaled": 0.41045688007287917, "test_loss_bbox_1_unscaled": 0.3538018821910688, "test_loss_bbox_2_unscaled": 0.28700053245778295, "test_loss_bbox_3_unscaled": 0.26223795865751376, "test_loss_bbox_4_unscaled": 0.23663100913451734, "test_loss_ce_unscaled": 1.370138221865247, "test_loss_ce_0_unscaled": 1.4795395280145536, "test_loss_ce_1_unscaled": 1.463806616272896, "test_loss_ce_2_unscaled": 1.4175632497307602, "test_loss_ce_3_unscaled": 1.3968758446395777, "test_loss_ce_4_unscaled": 1.383345760737255, "test_loss_giou_unscaled": 0.7866638697636356, "test_loss_giou_0_unscaled": 1.1066848164910723, "test_loss_giou_1_unscaled": 0.9927518037474079, "test_loss_giou_2_unscaled": 0.9150672205694163, "test_loss_giou_3_unscaled": 0.8769618766323016, "test_loss_giou_4_unscaled": 0.8350264885622984, "test_coco_eval_bbox": [0.0025538420077072395, 0.00785953672669776, 0.0012764198464959857, 0.002263049889529184, 0.0017684669320112308, 0.003754754519605244, 0.01362671087598188, 0.03070460682888716, 0.05339734524863692, 0.0036621445231624665, 0.028275972607074262, 0.09866316678023505], "n_parameters": 41302368

Mine: Epoch 0:"train_lr": 4.999999999999505e-05, "train_class_error": 86.52962853383647, "train_loss": 24.831565185072133, "train_loss_ce": 1.487930963236535, "train_loss_bbox": 1.106589217289985, "train_loss_giou": 1.5006296673657968, "train_loss_ce_0": 1.5683650821134938, "train_loss_bbox_0": 1.1501446843832621, "train_loss_giou_0": 1.5276848722439502, "train_loss_ce_1": 1.5325886286711992, "train_loss_bbox_1": 1.123001427258597, "train_loss_giou_1": 1.5115575443380058, "train_loss_ce_2": 1.5121202014369017, "train_loss_bbox_2": 1.1111633970119037, "train_loss_giou_2": 1.5037757965492, "train_loss_ce_3": 1.50199118992909, "train_loss_bbox_3": 1.102850424924895, "train_loss_giou_3": 1.4977243475104491, "train_loss_ce_4": 1.493773689155527, "train_loss_bbox_4": 1.1020243691680478, "train_loss_giou_4": 1.49764966567223, "train_loss_ce_unscaled": 1.487930963236535, "train_class_error_unscaled": 86.52962853383647, "train_loss_bbox_unscaled": 0.22131784346797476, "train_loss_giou_unscaled": 0.7503148336828984, "train_cardinality_error_unscaled": 8.113332769699019, "train_loss_ce_0_unscaled": 1.5683650821134938, "train_loss_bbox_0_unscaled": 0.23002893683180278, "train_loss_giou_0_unscaled": 0.7638424361219751, "train_cardinality_error_0_unscaled": 7.884004058167061, "train_loss_ce_1_unscaled": 1.5325886286711992, "train_loss_bbox_1_unscaled": 0.22460028544133848, "train_loss_giou_1_unscaled": 0.7557787721690029, "train_cardinality_error_1_unscaled": 7.846381467703754, "train_loss_ce_2_unscaled": 1.5121202014369017, "train_loss_bbox_2_unscaled": 0.22223267934946825, "train_loss_giou_2_unscaled": 0.7518878982746, "train_cardinality_error_2_unscaled": 7.901234359147785, "train_loss_ce_3_unscaled": 1.50199118992909, "train_loss_bbox_3_unscaled": 0.2205700850200524, "train_loss_giou_3_unscaled": 0.7488621737552246, "train_cardinality_error_3_unscaled": 7.98922894825837, "train_loss_ce_4_unscaled": 1.493773689155527, "train_loss_bbox_4_unscaled": 0.22040487382161605, "train_loss_giou_4_unscaled": 0.748824832836115, "train_cardinality_error_4_unscaled": 8.010060872505917, "test_class_error": 80.43325092163086, "test_loss": 29.091288772583006, "test_loss_ce": 1.3773058178901671, "test_loss_bbox": 1.1983217752456665, "test_loss_giou": 1.5670134636878967, "test_loss_ce_0": 1.4929402511596679, "test_loss_bbox_0": 2.168620691108704, "test_loss_giou_0": 2.27720348072052, "test_loss_ce_1": 1.4675289775848388, "test_loss_bbox_1": 1.8921377227783203, "test_loss_giou_1": 2.0321483806610106, "test_loss_ce_2": 1.44651027469635, "test_loss_bbox_2": 1.5869037508010864, "test_loss_giou_2": 1.8327613271713257, "test_loss_ce_3": 1.4104847149848938, "test_loss_bbox_3": 1.3860033449172973, "test_loss_giou_3": 1.7168726323127748, "test_loss_ce_4": 1.389806844997406, "test_loss_bbox_4": 1.2449273197174073, "test_loss_giou_4": 1.603797945213318, "test_loss_ce_unscaled": 1.3773058178901671, "test_class_error_unscaled": 80.43325092163086, "test_loss_bbox_unscaled": 0.23966435492038726, "test_loss_giou_unscaled": 0.7835067318439484, "test_cardinality_error_unscaled": 13.2414, "test_loss_ce_0_unscaled": 1.4929402511596679, "test_loss_bbox_0_unscaled": 0.43372413773536683, "test_loss_giou_0_unscaled": 1.13860174036026, "test_cardinality_error_0_unscaled": 17.636, "test_loss_ce_1_unscaled": 1.4675289775848388, "test_loss_bbox_1_unscaled": 0.37842754497528075, "test_loss_giou_1_unscaled": 1.0160741903305053, "test_cardinality_error_1_unscaled": 19.011, "test_loss_ce_2_unscaled": 1.44651027469635, "test_loss_bbox_2_unscaled": 0.31738075041770936, "test_loss_giou_2_unscaled": 0.9163806635856628, "test_cardinality_error_2_unscaled": 18.7734, "test_loss_ce_3_unscaled": 1.4104847149848938, "test_loss_bbox_3_unscaled": 0.2772006685256958, "test_loss_giou_3_unscaled": 0.8584363161563874, "test_cardinality_error_3_unscaled": 15.0426, "test_loss_ce_4_unscaled": 1.389806844997406, "test_loss_bbox_4_unscaled": 0.24898546411991118, "test_loss_giou_4_unscaled": 0.801898972606659, "test_cardinality_error_4_unscaled": 13.2232, "test_coco_eval_bbox": [0.0021265858757609974, 0.0065877339439397616, 0.000909544949817166, 0.0019531160362775328, 0.002315354314435091, 0.00309375358162458, 0.01123688032113149, 0.026146422736634624, 0.04583708711623451, 0.0036212598786164564, 0.02612322054570953, 0.09013151771112456], "epoch": 0, "n_parameters": 41304416


### Decision: Applied!


## 2. Efficient Attention

reference: https://openaccess.thecvf.com/content/WACV2021/papers/Shen_Efficient_Attention_Attention_With_Linear_Complexities_WACV_2021_paper.pdf

'
q = softmax(q, dim=2)
k = softmax(k, dim=2)
global_context = torch.bmm(k, v.transpose(1,2))
attn_output = torch.bmm(global_context.transpose(1, 2), q)
attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, out_dim)
attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
'

Compare with DeTr

DeTr: Epoch 0:"train_lr": 9.999999999999342e-05, "train_class_error": 89.00132779228738, "train_loss": 25.428831253216895, "train_loss_bbox": 1.141616935950595, "train_loss_bbox_0": 1.1871701720376293, "train_loss_bbox_1": 1.1554074858948267, "train_loss_bbox_2": 1.1439687113450978, "train_loss_bbox_3": 1.137943878802128, "train_loss_bbox_4": 1.1363896374385078, "train_loss_ce": 1.5075451776998126, "train_loss_ce_0": 1.5827832080391577, "train_loss_ce_1": 1.545520452064869, "train_loss_ce_2": 1.5272149658112815, "train_loss_ce_3": 1.5174654086656643, "train_loss_ce_4": 1.512690750325655, "train_loss_giou": 1.5496716783805327, "train_loss_giou_0": 1.5780433469907547, "train_loss_giou_1": 1.559824980988905, "train_loss_giou_2": 1.5517085842884981, "train_loss_giou_3": 1.5462578174807293, "train_loss_giou_4": 1.5476080747200298, "train_cardinality_error_unscaled": 7.935445413961039, "train_cardinality_error_0_unscaled": 7.70012344426407, "train_cardinality_error_1_unscaled": 7.736556412337662, "train_cardinality_error_2_unscaled": 7.717244994588745, "train_cardinality_error_3_unscaled": 7.795522186147186, "train_cardinality_error_4_unscaled": 7.856246617965368, "train_class_error_unscaled": 89.00132779228738, "train_loss_bbox_unscaled": 0.2283233871030343, "train_loss_bbox_0_unscaled": 0.23743403444542385, "train_loss_bbox_1_unscaled": 0.2310814970249544, "train_loss_bbox_2_unscaled": 0.2287937422762766, "train_loss_bbox_3_unscaled": 0.22758877592249996, "train_loss_bbox_4_unscaled": 0.22727792757236726, "train_loss_ce_unscaled": 1.5075451776998126, "train_loss_ce_0_unscaled": 1.5827832080391577, "train_loss_ce_1_unscaled": 1.545520452064869, "train_loss_ce_2_unscaled": 1.5272149658112815, "train_loss_ce_3_unscaled": 1.5174654086656643, "train_loss_ce_4_unscaled": 1.512690750325655, "train_loss_giou_unscaled": 0.7748358391902663, "train_loss_giou_0_unscaled": 0.7890216734953773, "train_loss_giou_1_unscaled": 0.7799124904944525, "train_loss_giou_2_unscaled": 0.7758542921442491, "train_loss_giou_3_unscaled": 0.7731289087403647, "train_loss_giou_4_unscaled": 0.7738040373600149, "test_class_error": 80.61580662818471, "test_loss": 28.39839132272514, "test_loss_bbox": 1.1101688678097572, "test_loss_bbox_0": 2.0522844032117518, "test_loss_bbox_1": 1.7690094071588698, "test_loss_bbox_2": 1.4350026625736503, "test_loss_bbox_3": 1.311189791958803, "test_loss_bbox_4": 1.1831550450082038, "test_loss_ce": 1.370138221865247, "test_loss_ce_0": 1.4795395280145536, "test_loss_ce_1": 1.463806616272896, "test_loss_ce_2": 1.4175632497307602, "test_loss_ce_3": 1.3968758446395777, "test_loss_ce_4": 1.383345760737255, "test_loss_giou": 1.5733277395272711, "test_loss_giou_0": 2.2133696329821446, "test_loss_giou_1": 1.9855036074948158, "test_loss_giou_2": 1.8301344411388325, "test_loss_giou_3": 1.7539237532646033, "test_loss_giou_4": 1.6700529771245969, "test_cardinality_error_unscaled": 13.492834394904458, "test_cardinality_error_0_unscaled": 18.508757961783438, "test_cardinality_error_1_unscaled": 19.818471337579616, "test_cardinality_error_2_unscaled": 17.193869426751593, "test_cardinality_error_3_unscaled": 15.385350318471337, "test_cardinality_error_4_unscaled": 12.799164012738853, "test_class_error_unscaled": 80.61580662818471, "test_loss_bbox_unscaled": 0.2220337728785861, "test_loss_bbox_0_unscaled": 0.41045688007287917, "test_loss_bbox_1_unscaled": 0.3538018821910688, "test_loss_bbox_2_unscaled": 0.28700053245778295, "test_loss_bbox_3_unscaled": 0.26223795865751376, "test_loss_bbox_4_unscaled": 0.23663100913451734, "test_loss_ce_unscaled": 1.370138221865247, "test_loss_ce_0_unscaled": 1.4795395280145536, "test_loss_ce_1_unscaled": 1.463806616272896, "test_loss_ce_2_unscaled": 1.4175632497307602, "test_loss_ce_3_unscaled": 1.3968758446395777, "test_loss_ce_4_unscaled": 1.383345760737255, "test_loss_giou_unscaled": 0.7866638697636356, "test_loss_giou_0_unscaled": 1.1066848164910723, "test_loss_giou_1_unscaled": 0.9927518037474079, "test_loss_giou_2_unscaled": 0.9150672205694163, "test_loss_giou_3_unscaled": 0.8769618766323016, "test_loss_giou_4_unscaled": 0.8350264885622984, "test_coco_eval_bbox": [0.0025538420077072395, 0.00785953672669776, 0.0012764198464959857, 0.002263049889529184, 0.0017684669320112308, 0.003754754519605244, 0.01362671087598188, 0.03070460682888716, 0.05339734524863692, 0.0036621445231624665, 0.028275972607074262, 0.09866316678023505], "n_parameters": 41302368

Mine: Epoch 0:

Decision: 

## 3. Eigendecomposition for attention_weight

'
weight_U, weight_S, weight_V = torch.svd(attn_output_weights)
weight_VH = weight_V.permute((1,0))
weight_S_obj = torch.where(weight_S > weight_S.mean(), torch.zeros(weight_S.shape))
weight_S_ctx = weight_S - weight_S_obj
attn_output_weights_obj = torch.bmm(weight_U * weight_S_obj, weight_VH)
attn_output_weights_ctx = torch.bmm(weight_U * weight_S_ctx, weight_VH)
'

Compare with DeTr

DeTr: Epoch 0:"train_lr": 9.999999999999342e-05, "train_class_error": 89.00132779228738, "train_loss": 25.428831253216895, "train_loss_bbox": 1.141616935950595, "train_loss_bbox_0": 1.1871701720376293, "train_loss_bbox_1": 1.1554074858948267, "train_loss_bbox_2": 1.1439687113450978, "train_loss_bbox_3": 1.137943878802128, "train_loss_bbox_4": 1.1363896374385078, "train_loss_ce": 1.5075451776998126, "train_loss_ce_0": 1.5827832080391577, "train_loss_ce_1": 1.545520452064869, "train_loss_ce_2": 1.5272149658112815, "train_loss_ce_3": 1.5174654086656643, "train_loss_ce_4": 1.512690750325655, "train_loss_giou": 1.5496716783805327, "train_loss_giou_0": 1.5780433469907547, "train_loss_giou_1": 1.559824980988905, "train_loss_giou_2": 1.5517085842884981, "train_loss_giou_3": 1.5462578174807293, "train_loss_giou_4": 1.5476080747200298, "train_cardinality_error_unscaled": 7.935445413961039, "train_cardinality_error_0_unscaled": 7.70012344426407, "train_cardinality_error_1_unscaled": 7.736556412337662, "train_cardinality_error_2_unscaled": 7.717244994588745, "train_cardinality_error_3_unscaled": 7.795522186147186, "train_cardinality_error_4_unscaled": 7.856246617965368, "train_class_error_unscaled": 89.00132779228738, "train_loss_bbox_unscaled": 0.2283233871030343, "train_loss_bbox_0_unscaled": 0.23743403444542385, "train_loss_bbox_1_unscaled": 0.2310814970249544, "train_loss_bbox_2_unscaled": 0.2287937422762766, "train_loss_bbox_3_unscaled": 0.22758877592249996, "train_loss_bbox_4_unscaled": 0.22727792757236726, "train_loss_ce_unscaled": 1.5075451776998126, "train_loss_ce_0_unscaled": 1.5827832080391577, "train_loss_ce_1_unscaled": 1.545520452064869, "train_loss_ce_2_unscaled": 1.5272149658112815, "train_loss_ce_3_unscaled": 1.5174654086656643, "train_loss_ce_4_unscaled": 1.512690750325655, "train_loss_giou_unscaled": 0.7748358391902663, "train_loss_giou_0_unscaled": 0.7890216734953773, "train_loss_giou_1_unscaled": 0.7799124904944525, "train_loss_giou_2_unscaled": 0.7758542921442491, "train_loss_giou_3_unscaled": 0.7731289087403647, "train_loss_giou_4_unscaled": 0.7738040373600149, "test_class_error": 80.61580662818471, "test_loss": 28.39839132272514, "test_loss_bbox": 1.1101688678097572, "test_loss_bbox_0": 2.0522844032117518, "test_loss_bbox_1": 1.7690094071588698, "test_loss_bbox_2": 1.4350026625736503, "test_loss_bbox_3": 1.311189791958803, "test_loss_bbox_4": 1.1831550450082038, "test_loss_ce": 1.370138221865247, "test_loss_ce_0": 1.4795395280145536, "test_loss_ce_1": 1.463806616272896, "test_loss_ce_2": 1.4175632497307602, "test_loss_ce_3": 1.3968758446395777, "test_loss_ce_4": 1.383345760737255, "test_loss_giou": 1.5733277395272711, "test_loss_giou_0": 2.2133696329821446, "test_loss_giou_1": 1.9855036074948158, "test_loss_giou_2": 1.8301344411388325, "test_loss_giou_3": 1.7539237532646033, "test_loss_giou_4": 1.6700529771245969, "test_cardinality_error_unscaled": 13.492834394904458, "test_cardinality_error_0_unscaled": 18.508757961783438, "test_cardinality_error_1_unscaled": 19.818471337579616, "test_cardinality_error_2_unscaled": 17.193869426751593, "test_cardinality_error_3_unscaled": 15.385350318471337, "test_cardinality_error_4_unscaled": 12.799164012738853, "test_class_error_unscaled": 80.61580662818471, "test_loss_bbox_unscaled": 0.2220337728785861, "test_loss_bbox_0_unscaled": 0.41045688007287917, "test_loss_bbox_1_unscaled": 0.3538018821910688, "test_loss_bbox_2_unscaled": 0.28700053245778295, "test_loss_bbox_3_unscaled": 0.26223795865751376, "test_loss_bbox_4_unscaled": 0.23663100913451734, "test_loss_ce_unscaled": 1.370138221865247, "test_loss_ce_0_unscaled": 1.4795395280145536, "test_loss_ce_1_unscaled": 1.463806616272896, "test_loss_ce_2_unscaled": 1.4175632497307602, "test_loss_ce_3_unscaled": 1.3968758446395777, "test_loss_ce_4_unscaled": 1.383345760737255, "test_loss_giou_unscaled": 0.7866638697636356, "test_loss_giou_0_unscaled": 1.1066848164910723, "test_loss_giou_1_unscaled": 0.9927518037474079, "test_loss_giou_2_unscaled": 0.9150672205694163, "test_loss_giou_3_unscaled": 0.8769618766323016, "test_loss_giou_4_unscaled": 0.8350264885622984, "test_coco_eval_bbox": [0.0025538420077072395, 0.00785953672669776, 0.0012764198464959857, 0.002263049889529184, 0.0017684669320112308, 0.003754754519605244, 0.01362671087598188, 0.03070460682888716, 0.05339734524863692, 0.0036621445231624665, 0.028275972607074262, 0.09866316678023505], "n_parameters": 41302368

Mine: Epoch 0:

Decision: 


