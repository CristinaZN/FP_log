## 1. AdaptiveResEncoder

'
encode_weight = torch.zeros((num_encoder_layers, d_model), device='cuda')
encode_weight[-1, :] = torch.ones((d_model), device='cuda')
self.encode_weight = nn.Parameter(encode_weight, requires_grad=True)
...
for i in range(6):
            mem += inter_mem[i] * self.encode_weight[i]
'

Compare with DeTr

DeTr: Epoch 0:"train_lr": 9.999999999999342e-05, "train_class_error": 89.00132779228738, "train_loss": 25.428831253216895, "train_loss_bbox": 1.141616935950595, "train_loss_bbox_0": 1.1871701720376293, "train_loss_bbox_1": 1.1554074858948267, "train_loss_bbox_2": 1.1439687113450978, "train_loss_bbox_3": 1.137943878802128, "train_loss_bbox_4": 1.1363896374385078, "train_loss_ce": 1.5075451776998126, "train_loss_ce_0": 1.5827832080391577, "train_loss_ce_1": 1.545520452064869, "train_loss_ce_2": 1.5272149658112815, "train_loss_ce_3": 1.5174654086656643, "train_loss_ce_4": 1.512690750325655, "train_loss_giou": 1.5496716783805327, "train_loss_giou_0": 1.5780433469907547, "train_loss_giou_1": 1.559824980988905, "train_loss_giou_2": 1.5517085842884981, "train_loss_giou_3": 1.5462578174807293, "train_loss_giou_4": 1.5476080747200298, "train_cardinality_error_unscaled": 7.935445413961039, "train_cardinality_error_0_unscaled": 7.70012344426407, "train_cardinality_error_1_unscaled": 7.736556412337662, "train_cardinality_error_2_unscaled": 7.717244994588745, "train_cardinality_error_3_unscaled": 7.795522186147186, "train_cardinality_error_4_unscaled": 7.856246617965368, "train_class_error_unscaled": 89.00132779228738, "train_loss_bbox_unscaled": 0.2283233871030343, "train_loss_bbox_0_unscaled": 0.23743403444542385, "train_loss_bbox_1_unscaled": 0.2310814970249544, "train_loss_bbox_2_unscaled": 0.2287937422762766, "train_loss_bbox_3_unscaled": 0.22758877592249996, "train_loss_bbox_4_unscaled": 0.22727792757236726, "train_loss_ce_unscaled": 1.5075451776998126, "train_loss_ce_0_unscaled": 1.5827832080391577, "train_loss_ce_1_unscaled": 1.545520452064869, "train_loss_ce_2_unscaled": 1.5272149658112815, "train_loss_ce_3_unscaled": 1.5174654086656643, "train_loss_ce_4_unscaled": 1.512690750325655, "train_loss_giou_unscaled": 0.7748358391902663, "train_loss_giou_0_unscaled": 0.7890216734953773, "train_loss_giou_1_unscaled": 0.7799124904944525, "train_loss_giou_2_unscaled": 0.7758542921442491, "train_loss_giou_3_unscaled": 0.7731289087403647, "train_loss_giou_4_unscaled": 0.7738040373600149, "test_class_error": 80.61580662818471, "test_loss": 28.39839132272514, "test_loss_bbox": 1.1101688678097572, "test_loss_bbox_0": 2.0522844032117518, "test_loss_bbox_1": 1.7690094071588698, "test_loss_bbox_2": 1.4350026625736503, "test_loss_bbox_3": 1.311189791958803, "test_loss_bbox_4": 1.1831550450082038, "test_loss_ce": 1.370138221865247, "test_loss_ce_0": 1.4795395280145536, "test_loss_ce_1": 1.463806616272896, "test_loss_ce_2": 1.4175632497307602, "test_loss_ce_3": 1.3968758446395777, "test_loss_ce_4": 1.383345760737255, "test_loss_giou": 1.5733277395272711, "test_loss_giou_0": 2.2133696329821446, "test_loss_giou_1": 1.9855036074948158, "test_loss_giou_2": 1.8301344411388325, "test_loss_giou_3": 1.7539237532646033, "test_loss_giou_4": 1.6700529771245969, "test_cardinality_error_unscaled": 13.492834394904458, "test_cardinality_error_0_unscaled": 18.508757961783438, "test_cardinality_error_1_unscaled": 19.818471337579616, "test_cardinality_error_2_unscaled": 17.193869426751593, "test_cardinality_error_3_unscaled": 15.385350318471337, "test_cardinality_error_4_unscaled": 12.799164012738853, "test_class_error_unscaled": 80.61580662818471, "test_loss_bbox_unscaled": 0.2220337728785861, "test_loss_bbox_0_unscaled": 0.41045688007287917, "test_loss_bbox_1_unscaled": 0.3538018821910688, "test_loss_bbox_2_unscaled": 0.28700053245778295, "test_loss_bbox_3_unscaled": 0.26223795865751376, "test_loss_bbox_4_unscaled": 0.23663100913451734, "test_loss_ce_unscaled": 1.370138221865247, "test_loss_ce_0_unscaled": 1.4795395280145536, "test_loss_ce_1_unscaled": 1.463806616272896, "test_loss_ce_2_unscaled": 1.4175632497307602, "test_loss_ce_3_unscaled": 1.3968758446395777, "test_loss_ce_4_unscaled": 1.383345760737255, "test_loss_giou_unscaled": 0.7866638697636356, "test_loss_giou_0_unscaled": 1.1066848164910723, "test_loss_giou_1_unscaled": 0.9927518037474079, "test_loss_giou_2_unscaled": 0.9150672205694163, "test_loss_giou_3_unscaled": 0.8769618766323016, "test_loss_giou_4_unscaled": 0.8350264885622984, "test_coco_eval_bbox": [0.0025538420077072395, 0.00785953672669776, 0.0012764198464959857, 0.002263049889529184, 0.0017684669320112308, 0.003754754519605244, 0.01362671087598188, 0.03070460682888716, 0.05339734524863692, 0.0036621445231624665, 0.028275972607074262, 0.09866316678023505], "n_parameters": 41302368

Mine: Epoch 0:

Decision: Applied!


## 2. Efficient Attention

reference: https://openaccess.thecvf.com/content/WACV2021/papers/Shen_Efficient_Attention_Attention_With_Linear_Complexities_WACV_2021_paper.pdf

'
q = softmax(q, dim=2)
k = softmax(k, dim=2)
global_context = torch.bmm(k, v.transpose(1,2))
attn_output = torch.bmm(global_context.transpose(1, 2), q)
attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, out_dim)
attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
'

Compare with DeTr

DeTr: Epoch 0:"train_lr": 9.999999999999342e-05, "train_class_error": 89.00132779228738, "train_loss": 25.428831253216895, "train_loss_bbox": 1.141616935950595, "train_loss_bbox_0": 1.1871701720376293, "train_loss_bbox_1": 1.1554074858948267, "train_loss_bbox_2": 1.1439687113450978, "train_loss_bbox_3": 1.137943878802128, "train_loss_bbox_4": 1.1363896374385078, "train_loss_ce": 1.5075451776998126, "train_loss_ce_0": 1.5827832080391577, "train_loss_ce_1": 1.545520452064869, "train_loss_ce_2": 1.5272149658112815, "train_loss_ce_3": 1.5174654086656643, "train_loss_ce_4": 1.512690750325655, "train_loss_giou": 1.5496716783805327, "train_loss_giou_0": 1.5780433469907547, "train_loss_giou_1": 1.559824980988905, "train_loss_giou_2": 1.5517085842884981, "train_loss_giou_3": 1.5462578174807293, "train_loss_giou_4": 1.5476080747200298, "train_cardinality_error_unscaled": 7.935445413961039, "train_cardinality_error_0_unscaled": 7.70012344426407, "train_cardinality_error_1_unscaled": 7.736556412337662, "train_cardinality_error_2_unscaled": 7.717244994588745, "train_cardinality_error_3_unscaled": 7.795522186147186, "train_cardinality_error_4_unscaled": 7.856246617965368, "train_class_error_unscaled": 89.00132779228738, "train_loss_bbox_unscaled": 0.2283233871030343, "train_loss_bbox_0_unscaled": 0.23743403444542385, "train_loss_bbox_1_unscaled": 0.2310814970249544, "train_loss_bbox_2_unscaled": 0.2287937422762766, "train_loss_bbox_3_unscaled": 0.22758877592249996, "train_loss_bbox_4_unscaled": 0.22727792757236726, "train_loss_ce_unscaled": 1.5075451776998126, "train_loss_ce_0_unscaled": 1.5827832080391577, "train_loss_ce_1_unscaled": 1.545520452064869, "train_loss_ce_2_unscaled": 1.5272149658112815, "train_loss_ce_3_unscaled": 1.5174654086656643, "train_loss_ce_4_unscaled": 1.512690750325655, "train_loss_giou_unscaled": 0.7748358391902663, "train_loss_giou_0_unscaled": 0.7890216734953773, "train_loss_giou_1_unscaled": 0.7799124904944525, "train_loss_giou_2_unscaled": 0.7758542921442491, "train_loss_giou_3_unscaled": 0.7731289087403647, "train_loss_giou_4_unscaled": 0.7738040373600149, "test_class_error": 80.61580662818471, "test_loss": 28.39839132272514, "test_loss_bbox": 1.1101688678097572, "test_loss_bbox_0": 2.0522844032117518, "test_loss_bbox_1": 1.7690094071588698, "test_loss_bbox_2": 1.4350026625736503, "test_loss_bbox_3": 1.311189791958803, "test_loss_bbox_4": 1.1831550450082038, "test_loss_ce": 1.370138221865247, "test_loss_ce_0": 1.4795395280145536, "test_loss_ce_1": 1.463806616272896, "test_loss_ce_2": 1.4175632497307602, "test_loss_ce_3": 1.3968758446395777, "test_loss_ce_4": 1.383345760737255, "test_loss_giou": 1.5733277395272711, "test_loss_giou_0": 2.2133696329821446, "test_loss_giou_1": 1.9855036074948158, "test_loss_giou_2": 1.8301344411388325, "test_loss_giou_3": 1.7539237532646033, "test_loss_giou_4": 1.6700529771245969, "test_cardinality_error_unscaled": 13.492834394904458, "test_cardinality_error_0_unscaled": 18.508757961783438, "test_cardinality_error_1_unscaled": 19.818471337579616, "test_cardinality_error_2_unscaled": 17.193869426751593, "test_cardinality_error_3_unscaled": 15.385350318471337, "test_cardinality_error_4_unscaled": 12.799164012738853, "test_class_error_unscaled": 80.61580662818471, "test_loss_bbox_unscaled": 0.2220337728785861, "test_loss_bbox_0_unscaled": 0.41045688007287917, "test_loss_bbox_1_unscaled": 0.3538018821910688, "test_loss_bbox_2_unscaled": 0.28700053245778295, "test_loss_bbox_3_unscaled": 0.26223795865751376, "test_loss_bbox_4_unscaled": 0.23663100913451734, "test_loss_ce_unscaled": 1.370138221865247, "test_loss_ce_0_unscaled": 1.4795395280145536, "test_loss_ce_1_unscaled": 1.463806616272896, "test_loss_ce_2_unscaled": 1.4175632497307602, "test_loss_ce_3_unscaled": 1.3968758446395777, "test_loss_ce_4_unscaled": 1.383345760737255, "test_loss_giou_unscaled": 0.7866638697636356, "test_loss_giou_0_unscaled": 1.1066848164910723, "test_loss_giou_1_unscaled": 0.9927518037474079, "test_loss_giou_2_unscaled": 0.9150672205694163, "test_loss_giou_3_unscaled": 0.8769618766323016, "test_loss_giou_4_unscaled": 0.8350264885622984, "test_coco_eval_bbox": [0.0025538420077072395, 0.00785953672669776, 0.0012764198464959857, 0.002263049889529184, 0.0017684669320112308, 0.003754754519605244, 0.01362671087598188, 0.03070460682888716, 0.05339734524863692, 0.0036621445231624665, 0.028275972607074262, 0.09866316678023505], "n_parameters": 41302368

Mine: Epoch 0:

Decision: 

## 3. Eigendecomposition for attention_weight

'
weight_U, weight_S, weight_V = torch.svd(attn_output_weights)
weight_VH = weight_V.permute((1,0))
weight_S_obj = torch.where(weight_S > weight_S.mean(), torch.zeros(weight_S.shape))
weight_S_ctx = weight_S - weight_S_obj
attn_output_weights_obj = torch.bmm(weight_U * weight_S_obj, weight_VH)
attn_output_weights_ctx = torch.bmm(weight_U * weight_S_ctx, weight_VH)
'

Compare with DeTr

DeTr: Epoch 0:"train_lr": 9.999999999999342e-05, "train_class_error": 89.00132779228738, "train_loss": 25.428831253216895, "train_loss_bbox": 1.141616935950595, "train_loss_bbox_0": 1.1871701720376293, "train_loss_bbox_1": 1.1554074858948267, "train_loss_bbox_2": 1.1439687113450978, "train_loss_bbox_3": 1.137943878802128, "train_loss_bbox_4": 1.1363896374385078, "train_loss_ce": 1.5075451776998126, "train_loss_ce_0": 1.5827832080391577, "train_loss_ce_1": 1.545520452064869, "train_loss_ce_2": 1.5272149658112815, "train_loss_ce_3": 1.5174654086656643, "train_loss_ce_4": 1.512690750325655, "train_loss_giou": 1.5496716783805327, "train_loss_giou_0": 1.5780433469907547, "train_loss_giou_1": 1.559824980988905, "train_loss_giou_2": 1.5517085842884981, "train_loss_giou_3": 1.5462578174807293, "train_loss_giou_4": 1.5476080747200298, "train_cardinality_error_unscaled": 7.935445413961039, "train_cardinality_error_0_unscaled": 7.70012344426407, "train_cardinality_error_1_unscaled": 7.736556412337662, "train_cardinality_error_2_unscaled": 7.717244994588745, "train_cardinality_error_3_unscaled": 7.795522186147186, "train_cardinality_error_4_unscaled": 7.856246617965368, "train_class_error_unscaled": 89.00132779228738, "train_loss_bbox_unscaled": 0.2283233871030343, "train_loss_bbox_0_unscaled": 0.23743403444542385, "train_loss_bbox_1_unscaled": 0.2310814970249544, "train_loss_bbox_2_unscaled": 0.2287937422762766, "train_loss_bbox_3_unscaled": 0.22758877592249996, "train_loss_bbox_4_unscaled": 0.22727792757236726, "train_loss_ce_unscaled": 1.5075451776998126, "train_loss_ce_0_unscaled": 1.5827832080391577, "train_loss_ce_1_unscaled": 1.545520452064869, "train_loss_ce_2_unscaled": 1.5272149658112815, "train_loss_ce_3_unscaled": 1.5174654086656643, "train_loss_ce_4_unscaled": 1.512690750325655, "train_loss_giou_unscaled": 0.7748358391902663, "train_loss_giou_0_unscaled": 0.7890216734953773, "train_loss_giou_1_unscaled": 0.7799124904944525, "train_loss_giou_2_unscaled": 0.7758542921442491, "train_loss_giou_3_unscaled": 0.7731289087403647, "train_loss_giou_4_unscaled": 0.7738040373600149, "test_class_error": 80.61580662818471, "test_loss": 28.39839132272514, "test_loss_bbox": 1.1101688678097572, "test_loss_bbox_0": 2.0522844032117518, "test_loss_bbox_1": 1.7690094071588698, "test_loss_bbox_2": 1.4350026625736503, "test_loss_bbox_3": 1.311189791958803, "test_loss_bbox_4": 1.1831550450082038, "test_loss_ce": 1.370138221865247, "test_loss_ce_0": 1.4795395280145536, "test_loss_ce_1": 1.463806616272896, "test_loss_ce_2": 1.4175632497307602, "test_loss_ce_3": 1.3968758446395777, "test_loss_ce_4": 1.383345760737255, "test_loss_giou": 1.5733277395272711, "test_loss_giou_0": 2.2133696329821446, "test_loss_giou_1": 1.9855036074948158, "test_loss_giou_2": 1.8301344411388325, "test_loss_giou_3": 1.7539237532646033, "test_loss_giou_4": 1.6700529771245969, "test_cardinality_error_unscaled": 13.492834394904458, "test_cardinality_error_0_unscaled": 18.508757961783438, "test_cardinality_error_1_unscaled": 19.818471337579616, "test_cardinality_error_2_unscaled": 17.193869426751593, "test_cardinality_error_3_unscaled": 15.385350318471337, "test_cardinality_error_4_unscaled": 12.799164012738853, "test_class_error_unscaled": 80.61580662818471, "test_loss_bbox_unscaled": 0.2220337728785861, "test_loss_bbox_0_unscaled": 0.41045688007287917, "test_loss_bbox_1_unscaled": 0.3538018821910688, "test_loss_bbox_2_unscaled": 0.28700053245778295, "test_loss_bbox_3_unscaled": 0.26223795865751376, "test_loss_bbox_4_unscaled": 0.23663100913451734, "test_loss_ce_unscaled": 1.370138221865247, "test_loss_ce_0_unscaled": 1.4795395280145536, "test_loss_ce_1_unscaled": 1.463806616272896, "test_loss_ce_2_unscaled": 1.4175632497307602, "test_loss_ce_3_unscaled": 1.3968758446395777, "test_loss_ce_4_unscaled": 1.383345760737255, "test_loss_giou_unscaled": 0.7866638697636356, "test_loss_giou_0_unscaled": 1.1066848164910723, "test_loss_giou_1_unscaled": 0.9927518037474079, "test_loss_giou_2_unscaled": 0.9150672205694163, "test_loss_giou_3_unscaled": 0.8769618766323016, "test_loss_giou_4_unscaled": 0.8350264885622984, "test_coco_eval_bbox": [0.0025538420077072395, 0.00785953672669776, 0.0012764198464959857, 0.002263049889529184, 0.0017684669320112308, 0.003754754519605244, 0.01362671087598188, 0.03070460682888716, 0.05339734524863692, 0.0036621445231624665, 0.028275972607074262, 0.09866316678023505], "n_parameters": 41302368

Mine: Epoch 0:

Decision: 


